{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKBcsRWSYyp7",
    "outputId": "c807b644-de8e-4d04-a7dd-aa360f5ec8d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\FYDP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0\n",
      "torchvision version: 0.16.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor , Lambda\n",
    "# from torch.nn.utils import spectral_norm\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# print(\"Python Version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuN3PEDlY5_d",
    "outputId": "062ffc98-6d19-4568-a9ad-66607588d9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001AE72BB29D0>, <torch.utils.data.dataloader.DataLoader object at 0x000001AE72BB2940>)\n",
      "Length of train dataloader: 391 batches of 128\n",
      "Length of test dataloader: 79 batches of 128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def scaleTransform(x):return (x*2) -  1\n",
    "\n",
    "# def scaleTransform(x):\n",
    "\n",
    "filecontent = \"\"\"\n",
    "def scaleTransform(x):\n",
    "    return (x*2) -  1\n",
    "\"\"\"\n",
    "with open('utils.py' , 'w') as f:\n",
    "    f.write(filecontent)\n",
    "from utils import scaleTransform\n",
    "\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=torchvision.transforms.Compose([ToTensor(), Lambda(scaleTransform)]), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([ToTensor(),Lambda(scaleTransform) ]) \n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True , # shuffle data every epoch? , \n",
    "    num_workers=6, pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,num_workers=6,pin_memory=True,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BGWOmRjtqBN"
   },
   "source": [
    "\n",
    "### Conditional BatchNorm \n",
    "https://arxiv.org/pdf/1707.00683v3.pdf\n",
    "- Normal Batchnorm are used to stablise gan training , thus making convergence faster\n",
    "- Just like simple concatenation and using embedding layers at the start, \n",
    "- For Conditional BatchNorm, each class has its own weight and bias, and each class has its own value of beta and gamma\n",
    "\n",
    "\n",
    "### Spectral Normalisation \n",
    "https://arxiv.org/pdf/1802.05957v1.pdf\n",
    "- it is a weight normalisation technique that prevents vanishing/ exploding gradients, by rescaling the weight tensor with spectral norm σσ of the weight matrix\n",
    "- It is an alternative to to using gradient penalty to enforce the 1-Lipschitz Continuity, thus another method to stablising the training\n",
    "- It is computationally cheaper than gradient penalty, thus allowing better performance in shorter amount of training time\n",
    "- Loss function : the Spectral Normalisation paper achieved best results with hinge loss, so I tried the hinge loss\n",
    "\n",
    "### Hinge Loss \n",
    "https://arxiv.org/pdf/1705.02894.pdf\n",
    "-  Based on support vector machines classifier\n",
    "- The discriminator learns a boundry between real and fake samples, that the real and generated images are the furthest apart \n",
    "- The generator will generate images closer to the boundry found by the discrminator\n",
    "- It is shown in paper that it increases stability and alliviates mode collaspe\n",
    "- The \"theoretical results\" in the paper also shown that  Nash equilibrium between discriminator and generator is achieved (when none of the networks can make the other improve further)\n",
    "\n",
    "\n",
    "### Improvement from previous:\n",
    "- RLC regularisation\n",
    " Regularizing Generative Adversarial Networks under Limited Data https://arxiv.org/pdf/2104.03310.pdf\n",
    " ![image.png](data:image/png;base64,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)\n",
    "\n",
    "-Cifar 10 is a smaller dataset, which means the discriminator more prone to overfitting,\n",
    "-  RLC regularisation term is added to the discriminator loss to regularise the discriminator, regularising the discriminator\n",
    "- This is appropriate this regularisation method is to regularising the discrminator when there is limited data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Og0mm7shfViX"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        \n",
    "        try:\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "class BatchNorm2d(torch.nn.BatchNorm2d):\n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            self.weight.data.fill_(1.0)\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "\n",
    "class CategoricalConditionalBatchNorm(torch.nn.Module):\n",
    "    #implementation from https://github.com/t-vi/pytorch-tvmisc/blob/master/wasserstein-distance/sn_projection_cgan_64x64_143c.ipynb\n",
    "    # as in the chainer SN-GAN implementation, we keep per-cat weight and bias\n",
    "    def __init__(self, num_features, num_cats, eps=2e-5, momentum=0.1, affine=True,\n",
    "                 track_running_stats=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.num_cats = num_cats\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "        if self.affine:\n",
    "            self.weight = torch.nn.Parameter(torch.Tensor(num_cats, num_features))\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(num_cats, num_features))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "            self.register_buffer('running_var', torch.ones(num_features))\n",
    "            self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
    "        else:\n",
    "            self.register_parameter('running_mean', None)\n",
    "            self.register_parameter('running_var', None)\n",
    "            self.register_parameter('num_batches_tracked', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_running_stats(self):\n",
    "        if self.track_running_stats:\n",
    "            self.running_mean.zero_()\n",
    "            self.running_var.fill_(1)\n",
    "            self.num_batches_tracked.zero_()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            self.weight.data.fill_(1.0)\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input, cats):\n",
    "        exponential_average_factor = 0.0\n",
    "\n",
    "        if self.training and self.track_running_stats:\n",
    "            self.num_batches_tracked += 1\n",
    "            if self.momentum is None:  # use cumulative moving average\n",
    "                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n",
    "            else:  # use exponential moving average\n",
    "                exponential_average_factor = self.momentum\n",
    "\n",
    "        out = torch.nn.functional.batch_norm(\n",
    "            input, self.running_mean, self.running_var, None, None,\n",
    "            self.training or not self.track_running_stats,\n",
    "            exponential_average_factor, self.eps)\n",
    "        if self.affine:\n",
    "            shape = [input.size(0), self.num_features] + (input.dim() - 2) * [1]\n",
    "            weight = self.weight.index_select(0, cats).view(shape)\n",
    "            bias = self.bias.index_select(0, cats).view(shape)\n",
    "            out = out * weight + bias\n",
    "        return out\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return '{num_features}, num_cats={num_cats}, eps={eps}, momentum={momentum}, affine={affine}, ' \\\n",
    "               'track_running_stats={track_running_stats}'.format(**self.__dict__)\n",
    "\n",
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = list(model.children())\n",
    "    flatt_children = []\n",
    "    if children == []:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for child in children:\n",
    "            try:\n",
    "                flatt_children.extend(get_children(child))\n",
    "            except TypeError:\n",
    "                flatt_children.append(get_children(child))\n",
    "    return flatt_children\n",
    "\n",
    "\n",
    "#Architecture of discriminator and generator modified from https://github.com/dterjek/adversarial_lipschitz_regularization/blob/master/wgan_alp.py\n",
    "class Resnet_Block(nn.Module):\n",
    "    def __init__(self,filters,bn = True):\n",
    "        super().__init__() \n",
    "        layers = []\n",
    "        for _ in range(2):\n",
    "            if bn:\n",
    "                layers.append(nn.CategoricalConditionalBatchNorm(filters , 10) )\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append( (nn.LazyConv2d(filters, 3, padding ='same')))\n",
    "            self.sequentialbranch = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequentialbranch(x) + x \n",
    "\n",
    "class Resnet_Block_down(nn.Module):\n",
    "    def __init__(self,filters,bn = True):\n",
    "        super().__init__() \n",
    "\n",
    "        layers = []\n",
    "        if bn:\n",
    "            layers.append(CategoricalConditionalBatchNorm(filters , 10) )\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append( (nn.LazyConv2d(filters, 3, padding ='same')))\n",
    "        if bn:\n",
    "            layers.append(CategoricalConditionalBatchNorm(filters , 10) )\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append( (nn.LazyConv2d(filters, 3, padding ='same')))\n",
    "        layers.append(nn.AvgPool2d(2 , 2))\n",
    "        self.mainbranch = nn.Sequential(*layers)\n",
    "        self.sidebranch = nn.Sequential( (nn.LazyConv2d(filters, 3, padding ='same')) , \n",
    "                                         nn.AvgPool2d(2 , 2))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mainbranch(x) + self.sidebranch(x) \n",
    "        \n",
    "\n",
    "class Resnet_Block_up(nn.Module):\n",
    "    def __init__(self,filters,bn = True):\n",
    "        super().__init__() \n",
    "\n",
    "       \n",
    "        \n",
    "        self.bn1 =    CategoricalConditionalBatchNorm(filters , 10) \n",
    "        layers = []\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append( nn.Upsample(scale_factor=2))\n",
    "        layers.append( (nn.LazyConv2d(filters, 3, padding ='same')))\n",
    "        self.mainbranch1 = nn.Sequential(*layers)\n",
    "        self.bn2 =CategoricalConditionalBatchNorm(filters , 10)\n",
    "        layers = []\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append( (nn.LazyConv2d(filters, 3, padding ='same')))\n",
    "        self.mainbranch2 =  nn.Sequential(*layers)\n",
    "\n",
    "        # self.mainbranch = nn.Sequential(*layers)\n",
    "        self.sidebranch = nn.Sequential( nn.Upsample(scale_factor=2)  ,  nn.LazyConv2d(filters, 1, padding ='same') )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        skip = x\n",
    "        x= self.bn1(x, y)\n",
    "        x = self.mainbranch1(x)\n",
    "        x= self.bn2(x,y)\n",
    "        x = self.mainbranch2(x)\n",
    "\n",
    "        return x  + self.sidebranch(skip) \n",
    "        \n",
    "\n",
    "class Resnet_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.class_processing = nn.Sequential(nn.Embedding(10 , 50 ), nn.LazyLinear( 32*32))\n",
    " \n",
    "\n",
    "        self.initial_block_main = nn.Sequential(\n",
    "            nn.LazyConv2d( 128, 3, padding ='same') , \n",
    "            nn.ReLU() , \n",
    "            (nn.LazyConv2d(128, 3, padding ='same')) ,\n",
    "            nn.AvgPool2d(2 , 2), \n",
    "        )\n",
    "\n",
    "        self.initial_block_side = nn.Sequential(\n",
    "            nn.AvgPool2d(2 , 2),\n",
    "            ( nn.LazyConv2d( 128, 3, padding ='same'))\n",
    "        )\n",
    "\n",
    "        self.main_blocks = nn.Sequential(\n",
    "            Resnet_Block_down( 128 , False),\n",
    "            Resnet_Block(128, False),\n",
    "            Resnet_Block(128, False)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        self.final = nn.Sequential( \n",
    "            nn.ReLU(), \n",
    "            nn.AdaptiveMaxPool2d(output_size=1), \n",
    "            nn.Flatten() , \n",
    "            \n",
    "        )\n",
    "        self.class_embed = spectral_norm(nn.Embedding(10, 128))\n",
    "\n",
    "\n",
    "        self.finallinear = nn.LazyLinear( 1  )\n",
    "\n",
    "        \n",
    "        _ = self(torch.randn(128,3,32,32) , torch.randint(high = 10, size = (128,)))\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "        for child in get_children(self):\n",
    "            if  isinstance(child , nn.LazyConv2d ) or isinstance(child , nn.Conv2d ) or isinstance( child,( nn.Linear , nn.LazyLinear)):\n",
    "                child = spectral_norm(child)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x , y):\n",
    "        y= torch.reshape(self.class_processing( y), [-1, 1,32,32])  \n",
    "        concated= torch.cat(  (x,y) , dim = 1 ) \n",
    "        x = self.initial_block_main(x) + self.initial_block_side(x)\n",
    "        x = self.main_blocks(x)\n",
    "        x= self.final(x)\n",
    "        out = self.finallinear(x)\n",
    "\n",
    "        # x += torch.sum(self.class_embed(y) * x, dim=1, keepdim=True)\n",
    "        \n",
    "        #adding label information to discriminator via projection\n",
    "        #https://github.com/crcrpar/pytorch.sngan_projection/blob/master/models/discriminators/snresnet.py\n",
    "        #https://arxiv.org/pdf/1802.05637v2.pdf\n",
    "\n",
    "        return out #+ torch.sum(self.class_embed(y) * x, dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "class Resnet_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "\n",
    "        self.initial_linear = nn.Linear( 128, 4*4*128)\n",
    "        # self.class_processing = nn.Sequential(nn.Embedding(10 , 50 ), nn.LazyLinear(4*4))\n",
    "\n",
    "\n",
    "        self.main_blocks = nn.ModuleList(\n",
    "            [Resnet_Block_up( 128 , True),\n",
    "            Resnet_Block_up(128, True),\n",
    "            Resnet_Block_up(128, True)]\n",
    "        )\n",
    "\n",
    "        self.final = nn.Sequential( \n",
    "            nn.LazyBatchNorm2d() , \n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d( 3, 3, padding ='same'),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        _ = self(torch.randn(128,128) , torch.randint(high = 10, size = (128,)))\n",
    "        self.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "        for child in get_children(self):\n",
    "            if  isinstance(child , (nn.LazyConv2d , nn.Conv2d, nn.LazyLinear) )  :\n",
    "                child = spectral_norm(child)\n",
    "\n",
    "    def forward(self, x,y):\n",
    "        x = self.initial_linear(x) \n",
    "        x = torch.reshape( x , [-1, 128, 4,4])\n",
    "        # y = torch.reshape( self.class_processing(y), [-1,1, 4,4 ] )\n",
    "        # concat = torch.cat( ( x,y) ,dim =1 )\n",
    "        # x = self.main_blocks(x)\n",
    "        for block in self.main_blocks:\n",
    "            x = block(x,y)\n",
    "\n",
    "        x = self.final(x)\n",
    "\n",
    "        if not self.training:\n",
    "            # to generate images to calculate kid/fid\n",
    "            x = 255 * (x.clamp(-1, 1) * 0.5 + 0.5)\n",
    "            x = x.to(torch.uint8)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# test_dis= Resnet_Discriminator()\n",
    "# test_gen = Resnet_Generator() \n",
    "# # with torch.no_grad():\n",
    "#     outputs = test_gen(torch.randn( 128 , 128 ))\n",
    "# import numpy as np \n",
    "# model_parameters = filter(lambda p: p.requires_grad, test_gen.parameters())\n",
    "# params = sum([np.prod(p.size()) for p in  test_gen.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-b2Le8PjkGgx"
   },
   "outputs": [],
   "source": [
    "# pip install wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "f-gnIXcUjULb"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "import torch_fidelity\n",
    "import numpy as np \n",
    "import wandb\n",
    "import collections \n",
    "torch.manual_seed(1)\n",
    "\n",
    "def hinge_loss(dpred_real,dpred_fake ):\n",
    "    # https://arxiv.org/abs/1705.02894v2\n",
    "    return (-torch.minimum(torch.tensor(0.0, dtype=torch.float, device=dpred_real.device),dpred_real - 1.0,).mean()\n",
    "        - \n",
    "        torch.minimum(torch.tensor(0.0, dtype=torch.float, device=dpred_fake.device),-dpred_fake - 1.0,).mean())\n",
    "    \n",
    "import shutil, os\n",
    "\n",
    "\n",
    "def rlc_reg( dpred_real,dpred_fake) -> torch.Tensor:\n",
    "    regularization_loss = (dpred_real -1.0).norm(dim=-1).pow(2).mean()  + (dpred_fake -1.0).norm(dim=-1).pow(2).mean()\n",
    "    return 0.15* regularization_loss\n",
    "\n",
    "def r1_reg( dpred_real,dpred_fake) -> torch.Tensor:\n",
    "    regularization_loss = (dpred_real -1.0).norm(dim=-1).pow(2).mean()  + (dpred_fake -1.0).norm(dim=-1).pow(2).mean()\n",
    "    return 0.15* regularization_loss\n",
    "\n",
    "\n",
    "def discriminator_loss(dpred_real,dpred_fake,real_img):\n",
    "    return hinge_loss(dpred_real,dpred_fake)  + r1_reg(dpred_real, real_img)\n",
    "    \n",
    "def generator_loss(pred):\n",
    "    return -torch.mean(pred)\n",
    "class GAN(LightningModule):\n",
    "#https://pytorch-lightning.readthedocs.io/en/stable/model/manual_optimization.html\n",
    "    def __init__(self,\n",
    "                 discriminator , \n",
    "                 generator, \n",
    "                 dataloader,\n",
    "                 val_data,\n",
    "                 d_loss,\n",
    "                 g_loss,\n",
    "                 latent_dim: int = 128,\n",
    "                 lr: float = 0.0002,\n",
    "                 b1: float = 0.3,\n",
    "                 b2: float = 0.999,\n",
    "                 batch_size: int = 128 ,\n",
    "                 n_discriminator_updates = 1,\n",
    "                 metricfreq = 5,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.data = dataloader\n",
    "        self.n_discriminator_updates = n_discriminator_updates\n",
    "        self.val_data = val_data\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self.batch_size = batch_size\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "        self.epoch_counter = self.current_epoch\n",
    "        self.metrics = collections.defaultdict(list)\n",
    "       \n",
    "        self.automatic_optimization = False\n",
    "        self.metricsfreq = metricfreq\n",
    "        self.d_loss_epoch =[]\n",
    "        self.g_loss_epoch =[]\n",
    "    def forward(self, *z):\n",
    "        return self.generator(*z)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels= batch\n",
    "        imgs.requires_grad = True\n",
    "        # imgs = scaleTransform(imgs)\n",
    "\n",
    "        g_opt, d_opt = self.optimizers()\n",
    "\n",
    "\n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.latent_dim)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "\n",
    "        # train generator\n",
    "\n",
    "        # gen erate images\n",
    "        if batch_idx % self.n_discriminator_updates == 0:\n",
    "            # self.generated_imgs = self(z)\n",
    "\n",
    "            # # log sampled images\n",
    "            # sample_imgs = self.generated_imgs[:6]\n",
    "            # grid = torchvision.utils.make_grid(sample_imgs)\n",
    "            # self.logger.experiment.add_image('generated_images', grid, 0)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            # valid = torch.ones(imgs.size(0), 1)\n",
    "            # valid = valid.type_as(imgs)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            pred_false = generator_loss(self.discriminator(self(z, labels),labels))\n",
    "\n",
    "            g_loss = (pred_false)\n",
    "\n",
    "                \n",
    "            g_opt.zero_grad()\n",
    "            self.manual_backward(g_loss)\n",
    "            g_opt.step()\n",
    "            self.g_loss = g_loss\n",
    "            # self.g_loss_epoch.append(g_loss.item())\n",
    "\n",
    "\n",
    "    # train discriminator\n",
    "    # Measure discriminator's ability to classify real from generated samples\n",
    "        fake_img = self(z, labels)\n",
    "        realpred = self.discriminator(imgs , labels)\n",
    "        fakepred = self.discriminator(fake_img,labels)\n",
    "        d_loss = discriminator_loss( realpred,fakepred,  imgs  ) \n",
    "        \n",
    "        d_opt.zero_grad()\n",
    "        self.manual_backward(d_loss)\n",
    "        d_opt.step()\n",
    "        self.log('g_loss', self.g_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('d_loss', d_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        # self.log_dict({\"g_loss\": self.g_loss, \"d_loss\": d_loss}, prog_bar=True)\n",
    "        \n",
    "        # self.d_loss_epoch.append(d_loss.item())\n",
    "\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # n_critic = 5\n",
    "\n",
    "        lr = self.lr\n",
    "        b1 = self.b1\n",
    "        b2 = self.b2\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return opt_g, opt_d \n",
    "    \n",
    "    def scaleTransform(self,x):\n",
    "        return (x*2) -  1\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.data\n",
    "    def val_dataloader(self):\n",
    "        return self.val_data\n",
    "\n",
    "    def validation_step(self, b, bid):\n",
    "        pass\n",
    "\n",
    "    def on_validation_epoch_end(self, *args, **kwargs):\n",
    "        # print('validate')\n",
    "        # if self.current_epoch % self.metricsfreq:\n",
    "    \n",
    "        wrapped_generator = torch_fidelity.GenerativeModelModuleWrapper(self.generator, self.latent_dim, 'normal', 10)\n",
    "\n",
    "        metrics = torch_fidelity.calculate_metrics(\n",
    "            input1=wrapped_generator, \n",
    "            input2='cifar10-val', \n",
    "            input1_model_num_samples = 10000, #size of cifar10 validation set\n",
    "            cuda=True, \n",
    "            isc=False, \n",
    "            fid=False, \n",
    "            kid=True, \n",
    "            verbose=False,\n",
    "        )\n",
    "        # mean_d_loss= np.mean(self.d_loss_epoch)\n",
    "        # mean_g_loss= np.mean(self.g_loss_epoch)\n",
    "        # self.d_loss_epoch.clear()\n",
    "        # self.g_loss_epoch.clear()\n",
    "        self.log( \"kid\",  metrics['kernel_inception_distance_mean'] , prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        metricdict = {\"epoch\" : self.current_epoch, \"kid\":  metrics['kernel_inception_distance_mean'] }\n",
    "        # self.log_dict(metricdict, prog_bar=False)\n",
    "        # wandb.log(metricdict)\n",
    "\n",
    "        # for key , value in metricdict.items():\n",
    "        #     self.metrics[key].append(value )\n",
    "        print(metricdict)\n",
    "\n",
    "            \n",
    "        disstr = f\"Discriminator-Epoch{self.current_epoch},KID={metrics['kernel_inception_distance_mean']}.pth\"\n",
    "        genstr = f\"Generator-Epoch{self.current_epoch},KID={metrics['kernel_inception_distance_mean']}.pth\"\n",
    "\n",
    "            \n",
    "        # self.discriminator.save(disstr,save_format=\"tf\")\n",
    "        # self.generator.save(genstr\t, save_format=\"tf\")\n",
    "        torch.save(self.discriminator.state_dict(),disstr )\n",
    "        torch.save(self.generator.state_dict(),genstr )\n",
    "        # self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
    "\n",
    "        # Log the model as artifact.\n",
    "        dis_name = wandb.util.make_artifact_name_safe(f\"Discriminator-{wandb.run.name}\")\n",
    "        gen_name = wandb.util.make_artifact_name_safe(f\"Generator-{wandb.run.name}\")\n",
    "        dis_artifact = wandb.Artifact(dis_name, type=\"model\")\n",
    "        gen_artifact = wandb.Artifact(gen_name, type=\"model\")\n",
    "\n",
    "\n",
    "\n",
    "        dis_artifact.add_file(disstr)\n",
    "        gen_artifact.add_file(genstr)\n",
    "        wandb.run.log_artifact(dis_artifact, aliases=[\"latest\", f\"Discriminator_epoch_{self.current_epoch}\"])\n",
    "        wandb.run.log_artifact(gen_artifact, aliases=[\"latest\", f\"Generator_epoch_{self.current_epoch}\"])\n",
    "\n",
    "        # Remove the SavedModel from wandb dir as we don't want to log it to save memory.\n",
    "        os.remove(disstr)\n",
    "        os.remove(genstr)\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self, *args, **kwargs):\n",
    "        # z = self.validation_z.to(self.device)\n",
    "        num_cols =10\n",
    "        num_rows=5\n",
    "\n",
    "        random_latent_vectors = torch.randn(num_cols * num_rows, self.latent_dim).cuda() \n",
    "        generated_images = self.generator(random_latent_vectors,  torch.arange(0,10).repeat_interleave(5).type(torch.IntTensor).cuda()  ).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        generated_images = (generated_images +1 ) /2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        images = []\n",
    "  \n",
    "\n",
    "\n",
    "        plt.figure(figsize=(num_cols * 1.0, num_rows * 1.0))\n",
    "        for row in range(num_rows):\n",
    "            for col in range(num_cols):\n",
    "                index = row * num_cols + col\n",
    "                plt.subplot(num_rows, num_cols, index + 1)\n",
    "                plt.imshow(np.transpose(generated_images[index] , (1,2,0)))\n",
    "                plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # log sampled images\n",
    "        # sample_imgs = self(z)\n",
    "        # grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        # self.logger.experiment.add_image('generated_images', grid, self.current_epoch)\n",
    "\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar,Callback\n",
    "\n",
    "class MetricTracker(Callback):\n",
    "    #https://stackoverflow.com/questions/69276961/how-to-extract-loss-and-accuracy-from-logger-by-each-epoch-in-pytorch-lightning\n",
    "\n",
    "  def __init__(self):\n",
    "    self.collection = collections.defaultdict(list)\n",
    "\n",
    "  def on_train_epoch_end(self, trainer, ganmodule):\n",
    "    elogs = trainer.logged_metrics\n",
    "    self.collection['epoch'].append(ganmodule.current_epoch)\n",
    "    self.collection['d_loss'].append(elogs['d_loss_epoch'])\n",
    "    self.collection['g_loss'].append(elogs['g_loss_epoch'])\n",
    "  def on_validation_epoch_end(self,trainer, module):\n",
    "    if 'kid' in trainer.logged_metrics:\n",
    "            self.collection['kid'].append(trainer.logged_metrics['kid'])\n",
    "            d = {}\n",
    "            for k, v in self.collection.items():\n",
    "                d[k] = v[-1]\n",
    "            wandb.log(d)\n",
    "\n",
    "    # do whatever is needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"numpy<1.24.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4d5ba17edc8c43ccac89f11f3227206f",
      "e9b831e932144fab855bd0bb57c69c33",
      "83c8d91649364ee3b6cd0a4aa6b63b4b",
      "ffaf3c23e2f24062896d6cf843096d5e",
      "6ec1ffebd4b4418b872d546924f0f664",
      "49808b1b0be14ec39cdb9c7b4be822e6",
      "18b6a606df224826a14e07ba56fffec7",
      "12f2ecac2df547b8bd9d10718dc5ac5f",
      "856b843259324a3e93b3c6ffd16d966c",
      "927882da5d4d4c7897dedfbe3b9122a4",
      "46baf01cff3c48e78d6b903abf8c797c",
      "067592ab2588499b8497baa5662f4801",
      "2d59d9ea0fe94cde9f35947e00bb6f2e",
      "0ac57d6086ea4a98ba89d34bdd8c7363",
      "b73f362a987f4d69a107e3f98e5de240",
      "b40109c469dd44beb186c029c05db698",
      "dadb5bc7edc14fc2a07fae957684f13e",
      "bfd86bc3059f494aa5046f2687a76fa4",
      "35ad1df4704148f2a67d1be8e2ad6fa7",
      "5b52debba6564628b03ca3e41d03403f",
      "6b1280c851314ecdaf36378a5eb88caa",
      "59756976188943848534544548acaa9b",
      "d2d2239c525d4fb3b9434b7f0952c698",
      "3974a3844fad45d9ba52767152ffda58",
      "5516cbf4018b42c5801ded5f7927a43f",
      "978bb39acdb34534a372e09287a136e8",
      "7b960f7f12b9455e9d772abd7aace408",
      "888972bf9000400ba6323d3ff358583e",
      "2a4041aae6404e588fd1ecf4ca02b433",
      "10bc7ab1ff9942429c6cbc1153af32e1",
      "8c992fba2ff24bb49266b4ae87b97407",
      "387cf9dce823481f951feed7b8f96ee9",
      "9bec64807e45418484b2f19b130ecf8b",
      "91c8714e3edc49baa3b35caf3833cfed",
      "2b79793c31b546a0ac7d8b0bb3b6aa9e",
      "b7ed3b9987da42ea94865cbca80632b3",
      "6c0e0e9bf2bb4c4ab3eb988469fec8e5",
      "6e744277a04d46f4b30aa98e60975ff7",
      "9d18a8ce28274f648b007ed131dabea0",
      "06c69ca537a248a0815996bde1aeda9e",
      "872208a14c8b49ac907c40c26d40439a",
      "fcd52fb25d594d97b37787d206e504a6",
      "f6445a4d22c84b3e8b21c6ceb2074faa",
      "4f66be21a6b642c89c1394aa114877ff",
      "a4546108ae54423c8fd3d4887d2192bd",
      "d6f985d0f1a1476399f5da5b3a14dff7",
      "0299e64ac012473eba83a170f91265cf",
      "bfe20b156ed2400d97eab00b6f649d49",
      "47a5c90c7cd746fd87087985056c1f42",
      "605a7f5cb2d14719ac15e1a0e3ce7b33",
      "46ac71b336c346a9b42184c585293636",
      "66e0295ba6984027a6ddb313dd4ee462",
      "f351d0e86b45456fa502e3466c533343",
      "07c4701ab0ec4c4fb0e3ec6fcd86d9fa",
      "312e776ee8804d618c0c051e1bc14d0c",
      "24b61010a6a545f881dffbe5cc0cc533",
      "1f61d16471314a73b3e8a3043d716b61",
      "42a0198f020747e4bf3f7f9addbb14d5",
      "b7ea658d60d947948bd9ba5ef74e4aef",
      "1520880a40ff48f28f00d4e2c7b1be0c",
      "fae1fb182e5e43f29f0bee020fc5d97f",
      "e06b3da7631e43dfa3d604f13ac6dc55",
      "84018d13f2d8401588a712f23e6c4e77",
      "6984a03077e34bd7b1ed176997973f37",
      "decea3aa6830428c96a3aea633ad3a9e",
      "ab2ab01388e842eea122a12df5f5e33a",
      "927471bbc52e4ec39ba246b06f74c2c6",
      "f3f4fabd355b4f709c3ea756da521f6e",
      "86a7a6bea835477486fea7a6c7c2ff81",
      "06d09197675942cebb820a26a65466ee",
      "6e4845d1c309461e990f7fe9f1c94378",
      "f247e2fa984e4c6ea8387ae30c75b729",
      "4b0b60bb9c9d41f99ee8faaf76d4480c",
      "248d61983d8c441d93cf9d9ff45a0f7c",
      "fc4c448bf06d4216ba884e5acc5603e2",
      "656f2da084884e5b9d6ab8ec3ac5b563",
      "3506b313e6884d4c8f03ac53644afbac",
      "0e72122ff7fc466e8deaeddaec39d794",
      "f39be73038f54a509608eca8fb7ee2c2",
      "837bdca7e02f45beb4342dcf9a58c3a5",
      "ae7a1fc5447f40f8ac2b3dd135f0b901",
      "91d5d81826854769b965e80982b57e26",
      "895956df394f44b2ba0801b397f05cbd",
      "daf6f59428b14bb7be28fb972a12e55c",
      "b669444f68a4496889f65bfd70a60728",
      "59cb14f8a1954bd4ae26baf9dcbe224b",
      "e428df4aefaf4cbcacdb87cdb1a9f5a9",
      "0cb5a7d62a764c58b1bf8e285faf7fc8",
      "19a322da4e2c4582bfa01b4a3e0f0fe5",
      "e80791e91c444bc49e4f048c7f5830db",
      "584d942fd2ef4bf1b1ea0c83202ec61d",
      "2014bcb7fa864b5c9e1aedc0141e2ea4",
      "6e911c28611d4c649c6e3ab942f58a9a",
      "3ded5a4eba254c2881da8c9c80d7cb51",
      "8720c9a18b054e60b373f81e1ad3717e",
      "9379e8a84f474a69a2585be326844979",
      "160c95afa8f74222b706e01c660d371d",
      "fa1b429776af4bc7a43ca7e0b9b88b9a",
      "e418f0eaafc1488e864751bb9325920b",
      "3655455817e342d385a78202f11aea1f",
      "31a8bc732da9473a99b8c2b8aabb7c84",
      "550b2c9b07ca4ead8e0eddc5c4ce2f4d",
      "efb6dc4f0d5f43f980bb769bf6e43295",
      "f5adfd7660fe492f88d2bfdfdc0aa9cb",
      "fc8014a23339495c83460c9574c3d3aa",
      "1a282080627149a9aacbbd276e82df3d",
      "37ff0230882a4676871ea9d0515787e4",
      "87c9236336674531ac81fa30068ada3d",
      "211f8608a7004fc9aaf50a51994a2044",
      "7290a12489bf48bba8b0db7f6d0bc997",
      "a6f0f5d9d86e45e99ea612adccf34964",
      "182dfdc7bc034f199a44ecda4a144d6b",
      "cc7cc50804e343d4bbb38a1978edafe0",
      "b40ac43265bf488ca596f9473cc390de",
      "049b77595a9b4795b70a306fba9f7162",
      "7a30dac73a964668b3d8d26ee7dfd7c5",
      "5f1258652d654fee824a827b21af2560",
      "61b43b9108dd47b29f8c07d9625d648c",
      "3140de05a3ef4e12a2ceafc7a72d0ccb",
      "98b9c641524041bda833f19abbfdb300",
      "8b74008c7f304c47849b85934157a2af",
      "c895eec0367f4ea59d07ddb191b748c4",
      "87223e793a5941e8a2240ca92dc03497",
      "51cd5354210e45499fe7c0c4a7f051fa",
      "9ae69d3263df4256a58eeb73dc534c7d",
      "69dbbf09d3874283b928eab5309230ad",
      "809189717428419dacbd19c2827c3284",
      "4f0a6346721e477d8d4a876a43fd3f88",
      "d62682005199446cb9a03b98595dd28c",
      "1df8a36ed4c543b4b3bc849ecb8f106a",
      "cb6cc5ab406441d89f93c6ff4693ff54",
      "bcc84da8e26a47db95b3588d298d0662",
      "fb419956d74b4b82a9875c045003b684",
      "e2f7e73022234558a660a0b894cf4b59",
      "bcb2740d1ec74eed803c22c653d5a62c",
      "b196f39142b24509824519826675bd5e",
      "e5a5b6fd0ffc437fa40407e69f75b11c",
      "dcb3b5d4fc064f40aafe3d8a488017a5",
      "c612429ce31a474e8f951feefc1f8a59",
      "75b385ca38ed4268afa3204d0200882b",
      "6c24df9133274ef5aba5d47a1a128ea0",
      "fa7a36f8212e4177baa6a03405eab7d3",
      "9b9c4498cbff4649ad5c0464c71cb718",
      "5d6ea1e23e604d4d8f6d78bf8ad98c0f",
      "de1588a8a7f744d09c04b96fc13aa3a7",
      "910204aa840e4dbf8d88dd05795f2ad7",
      "63b770bdbec7458f80367a728fef23cf",
      "bba9ce25eab0446c90f101b80bdace78",
      "8f3ba5cf9c7e4d69aefdae8a4cdca2c9",
      "83abe7b3fd6b4dc9bd3c3591e933f93c",
      "ca787e21a5d9455a99b4967ab80481bd",
      "852f5ca501874755b017d5971d9c3c32",
      "df487117f62e4050985c348a74d14410",
      "009283515e7648a0874e45b28b00929d",
      "a1ce1694bb654819ab0a0f6acfca2ef8",
      "0401b7c7e5344dc9b0b5625ec136825e",
      "cc8d9c86996e4725898ee2461bb5c293",
      "00414d10ddc04e98b4f470ac5e4b101d",
      "b84bce7514a748878648440bb8b8bc48",
      "76274a1ba0c344fbb1617ae0441a2fb4",
      "39425395bccf46038519e9e5e4f59f9c",
      "cfce01a9be954fefbc058945bd0c7794",
      "8533af1c1ab74fad8fb3440eb635b71a",
      "3c1108434d6749f587bd79e92a9f2c68",
      "0ff96f6c0caf45038a55aeb0686cbaf5",
      "469f932e9e774e248b95a8fe7178ccba",
      "1dcbdc08bca746e581fdb72fb62c354a",
      "745cbf7741e64a6c9a8d1b2272e00232",
      "ef3fdfe5e94b4fd5b661b731a18a95cf",
      "1afe7e613c4546558fdac09e05271b83",
      "d4af68acae9b4bdba694564773c55dfa",
      "8b0550d3dace4852ae43a46bbe729bd6",
      "7f09c079db43404784ef0026d2c856cf",
      "6bb22cc595fb40fe8f49e185bcc6acd4",
      "a606719ed4de4507b90d9b394cdc9b1c",
      "da062f145cde494fbf7622217f5b596c",
      "ddcd8856d6a74bd6a24e4ce506585144",
      "39650d11af8441cf80147b72cfd5db30",
      "521b6e2efc4d4e3da03a79a510df9727",
      "218245b1d2e74a90a69f5798c5ad1680",
      "07c4523efd414f8e8a35e2284091d26b",
      "c7797271140a43919848bfdb81ddc861",
      "77447e6dda5f4c79bd099a1a8c58f81b",
      "9b6b5231c74149b7b762c6f2c226fdd9",
      "e1d05787ffa94fca9588ca219ef117e6",
      "4ecc5c8d4ff14381b61b88b06d777b6b",
      "ce405bf72f054b28b6889ceeb9380d75",
      "abaf68af0c1149b69d1dae9883370591",
      "5c93fe25a1f94c3e913845eacbd489c6",
      "bec231f59b8540919f500e0569f9d164",
      "556ef3cfac5d445bb18821c45d6d7643",
      "d1a8222c05924a6694d8aac79e814d96",
      "64e4402dae8a4dc0aec63d53afbe12d6",
      "c81d4dd73c064caa9ecd110d61091e58",
      "ec10ee6d65454e02a3974f6172ac12f7",
      "a0f0b3c6958143dabd061e47582dfb12",
      "4565b2dbc46e4e359d85becf645c0fa9",
      "526d894a86994774adb68ed57c7a47ce",
      "69e85c58b178499aa784265cc1b5999f",
      "eab7d66e4dc446598e0f8bffa1f317dd",
      "a9467632232244eea225713f1a9ba83e",
      "4c0670fb0fc54bd0ae7d8c8dce3b87ad",
      "eb2aee29afec4fc0b8773416bb8edf0c",
      "8d50fcbe6a8444048fc26baf4773aa80",
      "c598ad20b99c47bdb8f607b4defe4211",
      "53197b3d60cc4a439dddb3b62e8f885a",
      "69b9a9e377de46b2b0a3b3f93e19eaee",
      "f2c016ec7269409f93e9fd22a7ed8a10",
      "70b53e977143484ca98210e3330adb01",
      "0d39bfd5f3054be7bbdbaa78d6923d69",
      "4233e681d76b4f99b71193aa066c5b2e",
      "25d5a603a6544caf863a0353b4a47f40",
      "a394cada763b4fd9bbb8eed919e45584",
      "644b50033b9749f68a2c7141b578ba9e",
      "46069b9d76d242a6bf3093d5cccf4d25",
      "371c8e097acd49ab883ffa13b3587cbd",
      "8bef47e8aafa40e2a037209464a31f05",
      "9a71ec10eb2a46fd8d1fc084b6eb8a59",
      "48ba26e2555944dfaf39a449d035341e",
      "57f06402046345c29675c25c7db3b0f3",
      "f2f81a34bf174730b7ab5ca3f4959d2d",
      "ebe2d39c45364545a5bcb759d97bf74e",
      "c1bc8ef1d1d843349068ca6972bcba94",
      "55cf1625a8c546b29e5323446abccdd6",
      "0d5b7291fb184c33a60bc11a1a619407",
      "6f68bfe48ba8454e875aea776dd39496",
      "ac7fd4787a324e29b1ff28850d0fa20f",
      "f940295c505849158c9c0f8fe5c0d6c9",
      "dcb640e53188481e9739b97e648b0f10",
      "e5785579e9c34f13ac67552738cc9cae",
      "bb741eeeb9ce4b7a9dcbb0815020de3f",
      "cf87113c8f404f9aab62e3579d5fb82b",
      "b8ab03e968ea4634a4408ea03fe9e79a",
      "35a055e3645e4059afffd9a1c52b8de4",
      "66290f29ecb74bb29e998e1a4cc24525",
      "27faf405f60349b385efbe3f45412900",
      "47f4add8e2e3407ea1c07248908fec5b",
      "79e803c397df4a29afc9f52d9f46646e",
      "44ee90511cff4d5c8d1d460057bbdb87",
      "9d16111f15d8482c88e9eb72a93abb36",
      "7af4f1ad54764ecc90f1ca39842dc9b1",
      "006d3148cbb445ab9affdfb572589402",
      "c677a11d81244f3f95f7ff151372df4b",
      "06111eb98e404a068a3233cd76069602",
      "a9528488649a4bb8a4587cf34d723cb1",
      "a1741da4bf144559a09db1a64ce2d050",
      "365f3662deac435e90dc7a4aa09e3cec",
      "b2b2a5e80112422481296ef2c6e64299",
      "e3181bef9dab4b39976f9edcadae9cdb",
      "6ed9347b11b646c4ac6e97e08a9d8aca",
      "6e09cb87da3a494386e53183401bb035",
      "9368eb7a5ef14e5690345eab23920053",
      "64c90df395f547d39d0261d9240d377a",
      "97257d8600be4d05822cb09334a84ab3",
      "637d41546ac24538a0f800d94d88184b",
      "29a71b1f15c848b7a77490bb90332a5d",
      "c4af179bd54c4e0f9316fac52dcd745e",
      "35cac4ab00e74d9693f66020b26afab4",
      "5baab982d995407f87a08c2fbb0e6683",
      "2b7a1cf02b3f4ab481d2a3be9cb44f6e",
      "4ea44a439d1a4c8dabd15e0500b2c7d4",
      "b43d7cd6ea97499380ec391f75db710f",
      "07f3a83000b34199a5d51eee70e43def",
      "fd7c5dd400f4491490ba1574b1f0c508",
      "c38bb198864a46c89f11c5f689271b82",
      "6bc031471b2641b88c4502d1c1bc42d0",
      "353a18ce36af4f45bee8f51c55e5e946",
      "0173ff0ab8e84e7db40f8ab331d8e751",
      "98d700d331ec460c8b06b127842105c5",
      "ffb5d3445aab48458ec7d1c073d6c285",
      "0ad5fa71c8e54a5586d1489dec57249a",
      "c09cc7bd0d89439a93dd66b66961443c",
      "ff9ed2d0270c47d7bb1b3da40bb32136",
      "c9a2c6b4375e4378b5c60f07a28d66e0",
      "3e2109201b7548b1a1c72ccaf4b3de9d",
      "1d13aecf74d04662a8899412b7c8029c",
      "72fb881924744661a2e6f2bf9f5911fe",
      "d6065ea4657e49a69f6c3db3dff2ebae",
      "5d0846c3e58c40dbbb68ae61c43a69f6",
      "e8697bd964924bd7b86525f8a69b3691",
      "a4f83adb55884607bd3c61ab28a98acb",
      "8a1f4e6b58f64808a5251e86932e1720",
      "2da12993026a4b0c930bc951966364d0",
      "7da0d381ada34373b889f47d20d9915e",
      "fd2b1dd1d69f4131a569588c42a71ec5",
      "3d1104263ed44b688d5d14eee86e070b",
      "34a61655787d47818d9d4ca5b73d2f83",
      "3d52fe8f2fff4beeaf7f032d25ec00e7",
      "88dd00a369c74fd583c0fa4db517d14a",
      "d485b0c5b7d449f09e06781437398452",
      "a3c065581d1a49678acef95690fc694a",
      "d5f20717f6744a24ad0f00a873f5a0e4",
      "18340b21655440f08953e968312d8eb9",
      "2b24a68b30ab47228c958262255a4ce0",
      "6d3f31f022fa460f90a40fcd7a88fe95",
      "7e6888e561e045b0830a121ae9a4de4e",
      "e4b3f56890c046bd86b74fd144188a98",
      "ff1b1c0fff70479e9710101381da98c5",
      "2633d0313686416cb4049679c0329d80",
      "80865fa2919b47d48642c07b77bd7aa7",
      "f029f8d7e8854402ab6accd727e95919",
      "7e7b0369c54c45c6a43cd449eb469da8",
      "77e6f74aa4bc4326a3c0f9ffae03f9e3",
      "3434d2d3e318433c9a24b080f3aa4b42",
      "3f4ea559b61d41f09d3108c338d5d064",
      "336a08e9d1554063a31a26e71d283927",
      "fdd87eed64af4b57871e65e54417d71b",
      "5f8da9cb507c4036ae36bc7bf3fcaeff",
      "c4bf011c48ea4da0bca07d5bafa05454",
      "a5396e5ce4c94431833df8f640239c5e",
      "74edf7bb49264cf9afc94c006e69bd3e",
      "80a508bf0d3044c1bd510361126a09d8",
      "299bdf0b47024d7296f0d9476ffdabe9",
      "0cd140bf84c14c35bbb3933bc18d0842",
      "9c6d3237e83b4f7ab3d60e79e8c446a2",
      "8d64627a3f8f4d3484f35f8d34678e52",
      "b5552d0992d04eecaf87a1a2afd6a95c",
      "fdb91af8ac4c4a609933199591faa43c",
      "33cb3fec42934127987efc43832607c2",
      "c90efced1528453d8ebf942ea08b2316",
      "078f6367334f492e9b6e7641312449e9",
      "9160794cfd35450e97ec19fec06f4532",
      "8b32b4ddc2ad419bb3d0f7ac9ee8cf40",
      "334715178b45400e958546724b9c664c",
      "a7c2efa7940c47faa18120093c7167d4",
      "4c119068ad464c718b77c643751c1726",
      "5c6588976e154c7599517fe04f0f07cc",
      "7df9f4f2fa85421584d16dd51c8dc953",
      "b511ce4b449a42cab69e7595451787ea",
      "02cb8eb9a6f7450290b84738b8586994",
      "9feaa180b508411b8793baae47a56c9f",
      "d9bb2399ab63428990b5babf37650539",
      "661cc45b39a54be7b8ed0cbc3bd69b46",
      "67c40ee126474ed4b9ffabe31a8f8fab",
      "23ba07f0a5df4f9087fdfbf80c643cec",
      "d2a2cac964834837b7d3407b807462a2",
      "109f0fe2845f4555b27868fc1d4a0922",
      "3b4101261ae944b4b6012ba79873ae3f",
      "30373fba499f4223aab1c62fc130b54c",
      "b2aea4eb83c44bc2ba1ec022fa78c4a9",
      "07bedfdf0e36473f815d88b83191a8f7",
      "336cc82a2b3b4d169b1f43a2fe6ff833",
      "d15da710b3db47f48eec3a07c825f60a",
      "9cc37109a4184818a68f3e4ffda55cd8",
      "f0ba2a71590248c79754cb05bd911107",
      "229e9dabea8c4af2a36b74100193767a",
      "b692e616dc1642a0b1a15fb0718254f6",
      "a278fdc8baf44e36889fa9d1d439f536",
      "4f6a4492406243f39ca538ed84157f4c",
      "536f73d9725b43d2a0c007a1eae4c97c",
      "f6bc2d11ee894a0d8238233218c78d0e",
      "aad79e7ba6594958a4d13f650235a033",
      "4ef4dd195a6b4f05b02111b40c702a72",
      "5c230b4d1dca4a4fabbf9a52314b309d",
      "1cde41ad77684ebe9de39c04b314a8e6",
      "10f13a97b64940489bde081d84395e54",
      "2f94ede7921941809eb0a8e45540aa98",
      "995b48bde862446f99c3d7bf3cdf597c",
      "4971580ec83c423cbeee45304f115279",
      "2d6dae086f0f412e89d4eb8e80994ef2",
      "6fc13eb44fbb466780ed6da1279abf1e",
      "79eb4557cb314bada063c7c31e946a34",
      "352ec5a53c0348cf8081b980aab3bb3a",
      "65c879d129254de592fb865a698e39fb",
      "41fe9760a8db4bc0945479b615dd57a5",
      "ca5f028d321143d18c0488086750cc10",
      "fb794fda40bf4e25a45b2e004009d681",
      "ebc5cd9ffaa64e4a928f765334d2d828",
      "1417375c2c934314b12021ae2c3673a6",
      "a7dad2a8f6954628a7432cf0b6f81cc0",
      "a7c55fe512d5472c988147c001a025df",
      "d56556fc344d45e0bf62327eddbc8a0b",
      "d5f3c0f6a21a4e00aabfb137084c9fbe",
      "86c52cd8180d485b9e0f736c300bd16a",
      "270e20d95f1a4440b2e036be35bb1981",
      "0664a534d9e44df99e9a7751f92a442a",
      "a5a729a20ab54996a7c476db69f47145",
      "363446cc16c348c38d8865e81aef3f76",
      "2a384d605451425f948c8718bf7e0dbc",
      "bbe8b03a0c1d4f74b5946529ba2685bc",
      "e7cbd6e88e164fe090ece8001320d125",
      "59f9d8b205e94159b61a507d92b53c26",
      "0621a37b4a7841a5829a919239f63665",
      "532ec57860854f1f9cd2e38db72ec26d",
      "767a3e919bcc46cfb4d5b0cb119a2ed2",
      "0bea17a688944597ab81ceb669c0e9b5",
      "5e247daac7654edd9aafe80d33fd4d0c",
      "9be4dbd196b546929d7d31325f6a9756",
      "ec21af21923647829afbc46df5d417ae",
      "2d179dd77e6a4426a1d8b958df4fa92b",
      "7dab6a4955ce4918bdb5549b36640602",
      "fc4a2c1387c64f8d9d09ecc0f1ad57b7",
      "63aef74cacb84061802d7455772611ca",
      "36a03792df8444cb93de8a163aa4ccff",
      "943fd08953864e88ae3aee2d5ce4d9e9",
      "c7d36d4056724a008874a0b6ad2f933f",
      "044a2a4190c342bf949165f061021a34",
      "52bb7e35438e422884384de00815bf5c",
      "91185234fb8341a48908a4aa6eec1c6c",
      "9212747a41604d92a2b4904ad6215606",
      "772a57c12c6f4bd48fcf0055eef6533a",
      "a69a569a56844c2c803fb0f6ee8aa18a",
      "368413585785466b8cb465cfa29be651",
      "379028a52b27419c95829e714370e515",
      "b8319edfa2ac421184508590f82b4ebd",
      "1f38c62b6f504f178f271abf8176736e",
      "769a4824f3bd4651a1833adf1c483314",
      "031057c6a2194a7f909a02e92125dc7b",
      "1a334ee2e6074b57950b7772f571c35c",
      "f8c5ef652cb346289f71892d590afcb3",
      "106291e758f04b7da78ba4ff20a9abc0",
      "9e7f3b7ec8734a52ab0b16a03da25033",
      "26755d8cb23547c692eda432a5ff4724",
      "3896924af3574b34a92c7fc81f7ae19e",
      "f5c822c25b2b4fd0b6945468ef21cc64",
      "aee1a84ac23b4ffbb16ad5292440d1f0",
      "5f8768601a8b425093dd23cba8cc5239",
      "d294732abacd40edb1655c539e708900",
      "3ddb388268ce432288a41f3753eb14aa",
      "d9bae2791c7a433f8920e7886a87d8e6",
      "bebcddd4120c4316acaa8c749759ad19",
      "e46678644ec542a6912d9cf2e5fdea03",
      "6618fcabeafc49bfbb942d550cc0a141",
      "7deb63e314ec48068326cebfb9083f14",
      "3c9eb73a20eb4aebae7d021f7b5d2518",
      "636872a400fc4038a71fc97b90c23e82",
      "4bb95c1556e74e7dadd878e2acac6ab3",
      "8a63b4ec8a704221854be7d7c9060363",
      "0a64036aeb474f6c913ea5b848fe7df4",
      "f85d08c3fda543a486792d221479c33c",
      "543a631ec4234fc9b841099a6131aab5",
      "6b54892aab04425292a5b4a733afc1fc",
      "b9eed4f65dd643709a24d1bd4eebc5d4",
      "7eeeff478aed4a5d9206a22101d7766f",
      "b9e83be728a34f4980352178bfb3b958",
      "4edc4e5e9ae14795bc56e37584f35d73",
      "e365cb7a4c2145c6a57039e65950dcc3",
      "dcb503c1fb3e4e0ba8f4994cf362dabb",
      "8ec70cbe3de640068e1f82b35bcb654c",
      "2438343566ce4f8aaeb9be27a1838161",
      "cd651008d1154fa3b81f3fb8470425a6",
      "4a16d7c2ab0849d996e1d927a0bd5914",
      "81ac6031f76a40d7bb7d09b264f8d065",
      "7d42059c19874a07a2d659fa33407c45",
      "08c7b865d7454ab3870a048924c2a7dc",
      "824520a5bd3a4a81b27994842c59ec30",
      "55db521808ec4726b3412bbf66f5df5b",
      "853b5bca618f49d8ac369b254cfb2241",
      "619aceaa345e4ab8a5f234222d9c8f59",
      "f074a47780a544df95c85566859e85dc",
      "7f4d4dbacd574bb294fd98edf3573d9e",
      "3b89fe71307f412bbecd06ea94be29ad",
      "ac92dd194437402fb6ee2d4c293b1981",
      "a378ad89c2174ddeb43ca029de213c81",
      "04c28aad0b2e4d929d129efdba765077",
      "c168bab0670b419fb6aaf57ca754c571",
      "00f3ac4e07154c57995d8f4cc76f133b",
      "167845608c99402e852f61edb0305e7b",
      "1d440e86360e4cc58206637e151957d5",
      "6d9227c1fd04491b9c8c08cf21a82f7a",
      "6b1fa2d8ba5a4d9eae8ef240a1b70d76",
      "e1d76c44d4df4391abcd1377e7f658a1",
      "fd63581cf3d94c2f94b5285aaa70215b",
      "64535a3ebbef43e3ad15f1b87d6c95a0",
      "72a47539305e4f178092b98402ccbd78",
      "b2c1ddf172514523a347336fec3a823c",
      "b584893927a342e9bd03103d85326ee0",
      "0c71b92ae5e2454aaf588f3d1b0a3001",
      "43f9503b1b9c4e13b38dcb99e6947617",
      "3815b811350f4b7e946db60967b6dab0",
      "d0e490bbaa5d49ef956214a0fb3b7d4f",
      "87a6e06ea9fe439eb0f34f92a8cd3764",
      "4b474b59fbcc4bf0b14099c2349c2e73",
      "3565b6f0638f4d0f821e0bd5bdfe9e1c",
      "1b8448ac7aa54b4ab1c9be95c428f0fd",
      "d85faa6905c7401592839c12378547e7",
      "f506a13fff6647baab9b00ff08291855",
      "cbf90480b4714c01a498e36777c093ac",
      "81653e2ec25a4df0927d382592a5cc80",
      "c1237bf5a3eb427ea7208f106773695c",
      "349d5a3eeaf644409cb2793392885190",
      "ef5bf616c68e4c3099961958325079bb",
      "445b2cdf09704ec0a03e0431178242ad",
      "90296fada238422980f04a40cc156525",
      "06b4868e428f409990394d0fe7ffd4a7",
      "bcb3015f76e843da9948adabe691a86c",
      "d531230a700e4a23b932f22fcc401e73",
      "c404e04c15bf44289ace2c2034ea7540",
      "29a2c10c6af44f5abfda23ae4e463a64",
      "302ce49a0be24df5b026a46b0ef96091",
      "e5c0b34cbd444c56964e3a6df326dc7a",
      "ed3169a7aa694838b4e5ac0fae8ab40c",
      "7cd685ad775849e3a8b9e53f328eac0b",
      "ee1c71fe4e884e288aa6bf6eecf784b9",
      "7d5dd14201dc450f92a38aca2b955bb1",
      "8fab8adc49cd49dbb938c2a62d0e9612",
      "0ba3ad8bdfec4cfcbf6d3511c2412001",
      "f1552f7e1a9c4970b74c60cde0b21203",
      "5bd079d522054b7fbfa9dc7f1df00e7b",
      "e94009f2c93c41169779835faa7d414f"
     ]
    },
    "id": "BhKrYRo7XaaL",
    "outputId": "535a0265-6fd7-4a4f-c34c-772825af84ea",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhimadriarka\u001b[0m (\u001b[33mganventure\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\User/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Documents\\FYDP\\wandb\\run-20231123_115013-e5lufgo1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ganventure/1cbn%20specnorm/runs/e5lufgo1' target=\"_blank\">warm-water-6</a></strong> to <a href='https://wandb.ai/ganventure/1cbn%20specnorm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ganventure/1cbn%20specnorm' target=\"_blank\">https://wandb.ai/ganventure/1cbn%20specnorm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ganventure/1cbn%20specnorm/runs/e5lufgo1' target=\"_blank\">https://wandb.ai/ganventure/1cbn%20specnorm/runs/e5lufgo1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\FYDP\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8264\\3940455073.py:5: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 391/391 [01:37<00:00,  4.03it/s, v_num=5, g_loss_step=-.610, d_loss_step=8.480] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏         | 1/79 [00:00<00:03, 23.68it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▎         | 2/79 [00:00<00:01, 46.62it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▍         | 3/79 [00:00<00:01, 69.92it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▌         | 4/79 [00:00<00:00, 76.79it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▋         | 5/79 [00:00<00:00, 90.76it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|▊         | 6/79 [00:00<00:00, 103.28it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|▉         | 7/79 [00:00<00:00, 112.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█         | 8/79 [00:00<00:00, 121.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▏        | 9/79 [00:00<00:00, 134.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▎        | 10/79 [00:00<00:00, 149.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▍        | 11/79 [00:00<00:00, 163.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|█▌        | 12/79 [00:00<00:00, 147.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|█▋        | 13/79 [00:00<00:00, 153.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|█▊        | 14/79 [00:00<00:00, 160.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|█▉        | 15/79 [00:00<00:00, 163.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 16/79 [00:00<00:00, 169.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|██▏       | 17/79 [00:00<00:00, 180.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|██▎       | 18/79 [00:00<00:00, 131.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|██▍       | 19/79 [00:00<00:00, 135.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██▌       | 20/79 [00:00<00:00, 139.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|██▋       | 21/79 [00:00<00:00, 143.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|██▊       | 22/79 [00:00<00:00, 146.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|██▉       | 23/79 [00:00<00:00, 149.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|███       | 24/79 [00:00<00:00, 151.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|███▏      | 25/79 [00:00<00:00, 155.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 26/79 [00:00<00:00, 157.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 27/79 [00:00<00:00, 160.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|███▌      | 28/79 [00:00<00:00, 162.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|███▋      | 29/79 [00:00<00:00, 165.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|███▊      | 30/79 [00:00<00:00, 167.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███▉      | 31/79 [00:00<00:00, 168.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████      | 32/79 [00:00<00:00, 169.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|████▏     | 33/79 [00:00<00:00, 172.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|████▎     | 34/79 [00:00<00:00, 174.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████▍     | 35/79 [00:00<00:00, 174.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████▌     | 36/79 [00:00<00:00, 176.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|████▋     | 37/79 [00:00<00:00, 177.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████▊     | 38/79 [00:00<00:00, 179.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████▉     | 39/79 [00:00<00:00, 181.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|█████     | 40/79 [00:00<00:00, 182.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 41/79 [00:00<00:00, 186.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|█████▎    | 42/79 [00:00<00:00, 191.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 43/79 [00:00<00:00, 195.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████▌    | 44/79 [00:00<00:00, 188.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████▋    | 45/79 [00:00<00:00, 192.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 46/79 [00:00<00:00, 196.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▉    | 47/79 [00:00<00:00, 201.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████    | 48/79 [00:00<00:00, 205.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 49/79 [00:00<00:00, 195.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████▎   | 50/79 [00:00<00:00, 199.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████▍   | 51/79 [00:00<00:00, 203.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 52/79 [00:00<00:00, 207.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 53/79 [00:00<00:00, 198.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████▊   | 54/79 [00:00<00:00, 202.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|██████▉   | 55/79 [00:00<00:00, 205.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████   | 56/79 [00:00<00:00, 209.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 57/79 [00:00<00:00, 213.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 58/79 [00:00<00:00, 204.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████▍  | 59/79 [00:00<00:00, 207.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 60/79 [00:00<00:00, 211.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 61/79 [00:00<00:00, 214.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 62/79 [00:00<00:00, 206.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|███████▉  | 63/79 [00:00<00:00, 209.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████  | 64/79 [00:00<00:00, 212.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|████████▏ | 65/79 [00:00<00:00, 216.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|████████▎ | 66/79 [00:00<00:00, 208.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 67/79 [00:00<00:00, 211.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|████████▌ | 68/79 [00:00<00:00, 214.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|████████▋ | 69/79 [00:00<00:00, 217.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|████████▊ | 70/79 [00:00<00:00, 220.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████▉ | 71/79 [00:00<00:00, 212.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|█████████ | 72/79 [00:00<00:00, 215.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 73/79 [00:00<00:00, 218.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|█████████▎| 74/79 [00:00<00:00, 221.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▍| 75/79 [00:00<00:00, 224.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 76/79 [00:00<00:00, 227.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|█████████▋| 77/79 [00:00<00:00, 230.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|█████████▊| 78/79 [00:00<00:00, 222.40it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 79/79 [00:00<00:00, 225.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "C:\\Users\\User\\anaconda3\\envs\\FYDP\\lib\\site-packages\\torch_fidelity\\datasets.py:16: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).view(height, width, 3)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "if __name__ == '__main__':\n",
    "    wandb.login(key = '04b7c2f62c8431e510e831fc18ac5e786a022591')\n",
    "    wandb.init(project = '1cbn specnorm')\n",
    "\n",
    "    gan = GAN(discriminator = Resnet_Discriminator() , generator = Resnet_Generator() ,dataloader = train_dataloader  , val_data= test_dataloader,\n",
    "                          d_loss = hinge_loss , g_loss = generator_loss)\n",
    "    tracker1 = MetricTracker()\n",
    "    trainer = Trainer(accelerator='auto' , max_epochs  = 100 ,callbacks = [TQDMProgressBar(1) ,tracker1]   , enable_model_summary=False ,num_sanity_val_steps=0 ,limit_train_batches=1.0, limit_val_batches=1.0)\n",
    "\n",
    "    trainer.fit( gan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMPWZWr7W_WG"
   },
   "source": [
    "### Incremental fit - decrease learning rate to 0.0002/4, allow parameters of both models to be fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "93ba31be268b4b15bb708d9460f88c44",
      "bef6baf837804ff19365f923fee7f65b",
      "6c5b449998c84415ad2cf01a927c69f6",
      "8d31b694a6ad4f9fa499511b83e5e0cb",
      "0d0e5eb7c300409089bd30308327c4aa",
      "14726096e1d44489bb9200c6d38ee17c",
      "6842ec7931a0454499e55b7f234da944",
      "dafd11a45cec4ad7802571a0938a8d5a",
      "207f3350a2cc43a187ddab80c1c061bb",
      "9c83cf48a3c4458d813416f8743732df",
      "ad9aacae50a74b5ebdbc3d90d11faf3b",
      "093b1fef733c4272a198581fbd9345f7",
      "dbf08331d693487fb341c1c77278670f",
      "c13ec84c56f24e98b9e6faba1d8af14c",
      "41c0bbc798f04892b558a666c9e36c87",
      "efcac82419da4715956d97b882e6990f",
      "66bb74ddea284da8a4b9681bc5a0b520",
      "c631dc3b257543b2821e4e2290da30df",
      "9ecf2776b8c34d1d9b29d0bb60ffc1fb",
      "6cb648b3296a475ea2fe94bff9f9192b",
      "6fc722d4bf1d455c9a8e9b8b168d670f",
      "c951e369bf394e18b11ebfcc8c304754",
      "136b105ec2fc40bfbe9a3a4bd5002716",
      "d9ca6bf238ce4a5cb2aa873860f77b98",
      "70cfdb61dfb84dac9bf5acffcfdddb7d",
      "5ba5784972cc4f44ac0c36a451b46db8",
      "b31c80e4dd924c23a25a801bcbd224f5",
      "6b08fbc13aca45ad915bd0fac8a5f20c",
      "c810e5b3c7664c698a13ec7f4b547526",
      "53beda9b3c844eab8585814df9b5247c",
      "1576ffe0c9224991a53f226f3d702ae6",
      "6a2b4977bd2c481f80fd61446874bc54",
      "ca5db6701a544c6a8315885ff6a546c2",
      "9c26287856d442588a185c7fdc3becd3",
      "02dbf3beddc641d7afd26cf8d46ccac5",
      "8413ee517056498c9cd9a7f437971067",
      "e6514cef064545fcbf13a3209c67cbde",
      "1ee1b9efd7464ca3a78ef33eb1f5a483",
      "6da35456a233418186805b10b5c71a04",
      "1d5b5c255f9b41b98a854e3258ec0c53",
      "511f7ce4f9f04b8abd64a670c2c3db16",
      "332a0b17e41f439191c7463a6156f2e2",
      "c7b68f9a96b945a393e2776e393eb312",
      "a841a8bb9bcc438b93debb0774057a4f",
      "c8d2caed01944221bbc601b06efd777b",
      "489f27c385ca4ad3b138c1d32ab8eeed",
      "e33b3db5b6704bf9b47298fa518fdb60",
      "a2f947f7f9df47e5bed56ff906ba3064",
      "443fee9684db48d09860ad7660f505fb",
      "5609d06758c74b8790e37c7443c5e025",
      "d6badccc23b24c3f9868265e50f9fdfb",
      "badfcac20f9a4badb30c7f68265b107c",
      "dc3bfeb726a043e58aa95f096b6133ec",
      "b203c3cd22214c47adaefaf46c698ac2",
      "f1cde4dc6acc47e7905b95b69c447c0a",
      "2c92b2383d894c51acbacf815aade4bf",
      "f0939cce2b9641249c256df01d11df58",
      "fbfcb4e27ee24447a62719134ae1b087",
      "3d2525c705e94bcab3bf950b191ad191",
      "f100da00e46d4bc68f4415dbf4da15b8",
      "56aeec2585244ca9a2afd645f18383f4",
      "9260e6d8f64b47deab2c2bf2ef83fe6e",
      "82b6ca80abec455fae3d12700fa0e8e9",
      "ee4272451477435f9eaf8a69d5cfc121",
      "d9b9a8b1869442a999187718ab43fb23",
      "f6f3443684104b9aaf13a4e95ea12200",
      "2fd0ce57cc0c4ff68e7496c91edab939",
      "1a3f2c5768cc4b8b918109a59c620387",
      "38b524022ba046e9a775c0c4bdc2d5bd",
      "2a7817540c154f40ba38f5f40b86705c",
      "3f5bb83be3a94050a542b5a25039e3a4",
      "f40e87ea9468436385eca0d9d6ddc521",
      "c766062465d7478aa57108a51b1a3fcd",
      "ab0bdcbe945e4d529311c8c7b0f837c8",
      "b7802298c51c4b269fdb987f95fc6ae4",
      "f3ef4f2499e64368b4065698fb7fd725",
      "79913ee511d244d1b73beb590dc9b18f",
      "ed5f1707a1d24f2cbca287ff14803e0d",
      "845ec1d7f56d46279b61248184077fed",
      "c001961c5ba04c02a487ab132c0ff4f4",
      "114c4c1191314dda928d2d70655f5dba",
      "ae52ea00f90348d39b514a6de5966cb6",
      "813e9070a62b44639e62185b1b505849",
      "3d1583e363f549648eb2c920d6deae4b",
      "ba873e664c8e46baaf029e4e3c32fb0b",
      "82df683b17644db6bece8505ad70db81",
      "6f35467d54324503b5bdf7024d8c7499",
      "70d69c7f8bbe4855818718d4de42ff00",
      "ea26afa644514758bc6067aa7dda5e28",
      "96ed1f7818124c27a5a7ce9c254ed7c2",
      "3b1b420370b64c7aa4d4de897ccec68e",
      "602175a4b76042c9aa00b0202fd5a7c7",
      "ac60c7b5f3364876b080165ba62bedf6",
      "65a7335b50e44ac88e6f9ce60025db77",
      "87f4b63b8fd744c9a140b9508f031572",
      "3053525b2b104bb39cb6aad6b8cadd31",
      "bd66a03a85d640e1b6fc3a899e1f13d7",
      "feb5c6dcea8d48cbabb5db68139f86ec",
      "027f2611f4324922822cd4a465b89e87",
      "78d6a43c12804685bbbe0bab5f906baa",
      "924ac77654e947abb15f09bbcf3fcc71",
      "3b0f90fbd1374df1acaf6656662d9af7",
      "470181559a074c549ebf922434ce01cf",
      "1bda82425a66418fb0cdb36ba74c5aef",
      "e9dc4600d3714e90a1118bdaee0312ea",
      "6d4b840af44741a38f096a3d6ec61720",
      "19eafe7c20584364b6ca433c9078ef28",
      "6f6328fb9b5341ed986f0c2a09a7de6e",
      "1c50f5682cd04506a3a045b4384e9f33",
      "fe29f6bdc31b44bea2b2dd21d4674de3",
      "7c66469ef3664db9b9d429adfd934b58",
      "b0eea5f494df481d998307701affbe75",
      "2cb2b035c7d14c97a7cbaaafa0781df0",
      "a30b7f78c2b04942b84a14748ee2c3ee",
      "afcac4ce993042f59d5f7fc18012d240",
      "0ec03eba9fde4ad7b4100e19eb6d9053",
      "a911a7a1ffe14797a14101411b368b65",
      "9d6ea84972be47f49885def58ca36f03",
      "75fccbad6c6a406dbd7ba1f41e51618b",
      "f065b0ed376f4f61a1eeae76b73d0cbb",
      "95645dc42e8b4fe2bf1dfd17ee5e6629",
      "7a1ded410fbb4a61a5a1e5ee1b8d0542",
      "f4a828ad57bf4218be1e3ac27b8289b9",
      "ba12d5308ef64dd8829ae137715a37fb",
      "ddccc7409459483c885716314440c0a6",
      "2d45568868dc4a49afea91d8de0798f7",
      "fa2029cd09da4cf7ba57f35ec2253f4a",
      "f7b037930eea4e28a5582e27ec50f6cb",
      "6d993347578040ac9200890d6bd3a9cd",
      "2f50845a7a43429eb48ed1a2abcf6061",
      "deafd3f365f142108e19975a0b36eb6e",
      "d14637e2364a4da58233f59e2f339286",
      "8865f019af0f4836b693917891537066",
      "23bcddbcd9f14b7095701858a922292b",
      "e1cfe9cf74924a989e1324b480544780",
      "aaeb592f0fef4775824769dccd606a90",
      "3fbd5de6120f418990b7efaa5866da1f",
      "0efd34d4b35b46e8a6fc26413a9f6e57",
      "c0c8278395324538addee3d8eb6368cc",
      "dd1fd24293ea464c93334cc342180f27",
      "f84b0105df6544d2a7a9f46fb4c68ebe",
      "cb6537ef51e242cd90aaacfb83597bf6",
      "d9b1f340716f4b5fb0d8bfd6d19a317c",
      "cc3cc62cc0ba4373a0b45e69849bd3d9",
      "0b655d9071794278a1ad18847fb43d67",
      "e349c3bec1c94f98a875dd30011bc60a",
      "45e7d9affc594f08b4dde01481f1fd41",
      "cca360761e6244afa1560df30e0f1c33",
      "4398903c4b2f4e2495e4146e29b70ac4",
      "b768babba0a247478f9620e0cdd7a962",
      "91c7e0d896a44bdd9acbe234c2630c10",
      "449e9b2021d94660a543af34fca474f8",
      "5832d961b881434a8cde8630c1cf72e7",
      "bd324ad129dc4da5b0b3b3bbac731733",
      "c188b037c0a14585b995215dfd37e5cd",
      "0f69ac249c7044958b08ac663c5f0045",
      "e7b6a99170274de98d55670e3e98ba5f",
      "c6ef5ba5df7447288ed6bde3d0ca323a",
      "d33c61216bf844ecb1b930651ed2a625",
      "e24ecc28d9cb4211a1d9c0189b2eb56d",
      "0bfd90134e454d2bacbfaff7252a2f88",
      "e28ea429fc5149dab1d4b135b9d880ff",
      "ce0fb2b2553c430983b5dc6453b3de67",
      "86a541e677444ac19d880d2ccd6e1ccd",
      "d87ee9b9242e40e297fd78986441f1cf",
      "0ffd62de8329407e9d07f638ad463a14",
      "6d5232f36e614745af682f998f3b078b",
      "d2d6e81c4e174bd3b014dfaf330d226f",
      "bb0fee6f2e12430d97dd865a09963999",
      "8c41543f664c458fbbdb0e759a0e09bc",
      "40d496f2f25e444eb2550d6a49109b74",
      "2f7bde707f03470fb252f27905678e32",
      "676339addfed4ff89449aa0c7210f0cd",
      "91ebc4bc2bdb42a7ad57b6452500bfdf",
      "7162579588624583863844654dfb46b3",
      "d28b81d58b7a4d38b6ef48f01720de71",
      "7372ba3bfb7c4e93b467f23df4becd2e",
      "5a3c5cd5ed4a49e59cf7dd8edb7f9d80",
      "03e9e9f6960147459dea357f41559108",
      "0b7f20e18ceb4b1e973484dba2dfe9ba",
      "1ea60b8d4602490da9eed1e971d5ba17",
      "99dcd55b1e7340dfaddfc4423b1e751d",
      "ef8be3d6ad7f404f9d21733929f68f2c",
      "280ebddd030447f197a7b9ec46e5c77b",
      "6cc95a20885d47f28f54a4cc83914b8c",
      "d5cb7852a21b4becacdf939c77b0c0a9",
      "631077ddd9df4a8b9430946440e74e26",
      "947533fbb08f46a0ad81cfe8e1d590d9",
      "77b1ab2286c441dba6fd06298d6fefd5",
      "235da033e84d4b86a2b6f7837052fc54",
      "4e24fe3e7e974899be8f775901e4a871",
      "d6f1dbc5ab6d4bb9aab5474150f99941",
      "7acaf175f38b422eb7c18df85e62812c",
      "630c04375bfd43d3b762488ae0a24cec",
      "7953c5f938a143468330368611c0f923",
      "9e1a8c5b00054ec1b5436620c91567eb",
      "9678a68d014d49e08261cbd9fabc57d4",
      "9794fbc14f344be4b9bbdea1981e8993",
      "23e51142f2c34bc78badc164aa761da9",
      "cdaaef86bc2d498ea32917e856bd48c0",
      "dfefbca08d044f3e8cc3758da12574ce",
      "e54c9ce3396d4e61b8698dc4c0d4b633",
      "35e4c3ad0d88470c8984bc060f7e8415",
      "a431bb5bfead4a3eb491045c211ce807",
      "cd84e264eeae4a1fae8f3d7253d9b95f",
      "3b8d17e832fa4625b9515f4f7f9fa01a",
      "3457e5f37b874a529c9a8e0125fa071b",
      "f8847eceba934d11b7db02927ccf20c0",
      "21d9935971154a799f6c04b7e5c4e536",
      "70d1e28ee4a8407da5daf5625f78f451",
      "6880cad419f84ff8b67dd59c498e488d",
      "79dc7c5511b84861a80e840e468008fe",
      "5abc3c67566a417abc0ee983d8c85547",
      "e62c8199425a40d19397fc87b62a3c54",
      "a2315eae26e84162b838ff94f0638aea",
      "9347d92f28334154b783c1a98f4b887d",
      "b0708df00c1b47b8bef5ccff55d9afaa",
      "6250d41aff394c5aa82f452c8d0e8297",
      "1ebb21ea118d41ec97ca53af959d7080",
      "93146bd373234a569ae142bdb60b7952",
      "48430faf004746f08a7517b04bc1b2e0",
      "ec6d728229e84c5d8ad791e1e7e72d88",
      "7c2153ef94804efd94fad12d829d452c",
      "2e1be14dee764d98b78cb813e1dd6479",
      "e1d3f462cff44e2e91b6ca1cf06e66fd",
      "2970f84cc7c9441388c2cbfe88e52481",
      "752016808ea54860a0df03b2e6fb1c70",
      "6dd24d39e0ae4c8ca3385b68108c53fc",
      "359e98056dd346c8b4a7616f4825f00e",
      "b7b30a02915243ea944cd54c87fd7408",
      "050a1578785749519b668ffaa6394197",
      "758b9c795992415dab41bb5973249c4a",
      "51e33a3736c244c2891d068cd28f5274",
      "5084801e67a24b84b360a4862fb4b418",
      "b82f41ec12114e349e92a30179dac1eb",
      "03151b2f35b844a6990316dda67aaf94",
      "e9d5699fa98c46e6a2750d848bc56aac",
      "99fbcc7ba9354399b00c48defebda3f4",
      "e43793abca3d4fc6941c452076ac3497",
      "28ffcc14e7a7435493aaa3906601b89c",
      "afb14bc9cc9f407187b4333bdf3eee78",
      "58404077872f421e9bfc0be5bf4df0bb",
      "9a3cab216b6b4bfe9454c91ed89388a5",
      "de01625ef5db449490a8cc06f82c3492",
      "336c90e340a34cb4a398fc6a65e3040b",
      "5b0a204a2f384d53bdf5652dfbf2a6fc",
      "5d1fe76693f4480c94a77cb091c7a3e2",
      "dece226e0cca4928819a84cacce76bf5",
      "03c18989714a42008ee6271c84a1b41c",
      "2f555920a90a4f0781a415a0e64dbe9a",
      "3b6e10fa47d748c8869cfb33e8fb8013",
      "15cac4f0ecb5446aba72529a045c1b0c",
      "69985ea98dce4cd3956f66260ebc2c87",
      "3da4f391ccd94efb9c2d8287b9ab2264",
      "3f654a404c304edc9c818696fdf4c76b",
      "e93f4ecb4d384964851bc061579d23b3",
      "729e396eeb7c4e61b7b99b74d7a357e9",
      "2b4ad5a9b7734ceeb27dc89a35c3de94",
      "5e17ead09c254c8782f9d17bd755c34c",
      "61304650ca22451f87d1cab54c441ad5",
      "8f82f4c721c6417887ed378fb1937d66",
      "89327fc3ba8e47bd9d7e043b5d8bd648",
      "7ebd1b04d0974372af6976467ae9d502",
      "5c1e91c805a2472ebf4c3b661b50a700",
      "08280c9d5e424d009563fc00ad88b10c",
      "9ba4e5580ec44d7abfbcc48b986ca1a2",
      "7040d3a6020e4dc8a8c2519dc0fa1625",
      "51318f0396984f10aa3708ab7f47249d",
      "dd156fd967134afc982c7530d7778986",
      "b26a0a33d872434fb3a8bdaaac8162cb",
      "91919b78f0474fe689591f8da268a8cb",
      "27708d5f6d11443fb02b5cb7a8981f20",
      "becfa726358d4117859ff4b371e6ba11",
      "d098ff341f7247aa82a2e7f12c224957",
      "db9a7e7e664d4ed4bbf9601f36dc6136",
      "a138e46cf61b4de1b4f849f3ddfabd3b",
      "ec9cea36251542e8862b9dfe36c6b8be",
      "f520ebc9b8bf405ea58f460927f888c6",
      "4915a46f511f4cc2970ac5a008833dac",
      "8e87396fa34d4940912b6cb90b48389c",
      "c9bdc1c9c07d45f4ae291ab3c5856c07",
      "092a7a7f49b24e61aec311d3e667e7ec",
      "57b1a4a48cab479bb9cdc02c0424c740",
      "d8ceb183cfb9494096875c61c6c20f6a",
      "f0ea803e710d455d8704a0803ad22e0c",
      "c7d7395788f9498e9c57479578249b5b",
      "bfd72d0962784a2db14a2afb12b100ff",
      "2f368d77d20344a48c0570a7c43f510f",
      "f9fc87973b3043e4b7f7d910696f2f39",
      "72c5c368746848019d9f5fcc70d758b8",
      "3383ab99ecf345b6b646f1b516ed25d0",
      "8635707e0ef244cfb924ec06962db2cf",
      "f246b28f6f8b477392e8b95c58c928f5",
      "7923a82e24d24c07a91e156610ca72c2",
      "2d23651fc51245229167fe81a26085d0",
      "7032851e6c4b48bd94b4f95845ba45a7",
      "ec98d4f235c94ba189536b57c478873b",
      "f5bfeb73e35547d0a8cbad2565f93c57",
      "a07c1c07f42d4f2b9822a2f5fb078751",
      "410009335d1b459b9a8961cda518ed6c",
      "d426b93845ce42fcae51b6d52d216f83",
      "771a3af356f14cbc83720ceb7d286a24",
      "4150ee32d0a849059173d1784275f74d",
      "2355eb6ed77b4389bbff1470c6305a20",
      "e4c73502dc1e4fca9ce3fbd66885680e",
      "f33a4972cce04f72b1844ba22aebed7e",
      "b178d45574b941ea99f755eff88ddc52",
      "3c6f252f12c64f02b7dc99a617bc72ad",
      "b0b0cee6661d4aac81a54a746ade700d",
      "6d374f49a6c5456795cc2ec4cf56e3fc",
      "0de3743efa4d444da55baff50b90032b",
      "069beaedee5140aca631afd3a2f0b70d",
      "678ef541d40b408f97bf5858225fe391",
      "96baf6746f224c86b38a064acc85a74f",
      "fda78ce46e7c433f96cd6e86a2cc903e",
      "09cefa554e524f47b37ac1ae4dd3b260",
      "2096503ec72241b089ba24b616eb02bb",
      "8191fbaf57d44ef196d5fdbecdcf3758",
      "c8ecc96f96924e678eb39a0115fdb641",
      "b3f7fa1a1df64e99b320554cdebf74f1",
      "8cdebe7ed16b4a06906d0dbbcab7ca9a",
      "1145edc87c2e4e5bbc0222fce6f759bf",
      "5f749680ef404b9a846a46f7bc816eff",
      "3a78aaa5d5624720aafc58859d7cff2f",
      "2524a3becf29498eaf7f3e396a73daa2",
      "aeec3ccb1b524c5eae374474a86c0903",
      "c7b1eb43d3fe442586b40fedb90fdada",
      "f58b25599fcd4f1e9180425c5d0bb4f1",
      "2cdebb768149432a9e70075efd7742a8",
      "b4778b1ac8e74269bd80b4a1fa55f646",
      "9ad2da3ea88c4f718ff8fbc302988cd0",
      "27fbe53153d942d3b379edf44c379cc3",
      "398dea21c8034089b6b9f9882c4cd4b6",
      "6e9f60692d33401084dc27f4cd24ce0a",
      "e3aa2b4b4de74b859dd2c9011a4f1d02",
      "b7a0206756e7441f8b6f3a4c2805b787",
      "b68f680090f4439689af64440f754121",
      "06d3de7466eb4fc7902dc69874787da0",
      "b8e9d25ebc5849ca9d45347fc6b4975d",
      "b1cf0abbbd194346a35b49aba021e20a",
      "a9979fb1f31f415598c9024596995da7",
      "db760c13984a458fb9949f1720cb0a72",
      "d9f87b496f8549e48e19f10be9d71eb4",
      "cb1a1d957535479f9cc6434430543811",
      "db44bc8d43524c9d98fae163b5276f03",
      "44154f9d60a9417a8b3eff429af0fd7a",
      "7af1ee62588d48b490f65dacb63351ba",
      "99c256357dcc4e47b7e686d8b5517860",
      "de238ce780914190b0a44b35d4a4e792",
      "2787acc9e80d4b0d811d1aaf480df704",
      "aebca2f94d9e4450af7dc0fe2e0b77b6",
      "7768c238d73448f7b71bc84552c08d90",
      "4bb186bfbcd440ce98d02fa6f792c585",
      "0f55be445d7a4d65902083cb84492fe2",
      "aa7baa19f121490d90e2cee494167ddf",
      "8f8754cb153940eda0a776e7534e4e2a",
      "ae5d4404ba2743f2aa063ae255f6c63e",
      "c8207efa2793419092311d19caa9436a",
      "ad8e101696794805af8785ee5eeacfd8",
      "a4b7a15842fc48ca8ba51b700e1b8e34",
      "4d0746673ca84971b0732bb4a13853fa",
      "abd3f62b79e747ca948c7313c6760382",
      "f50bcb870844470ca4418b9ab6a85e12"
     ]
    },
    "id": "BlB-CwerjULc",
    "outputId": "771cbedb-c883-48aa-f1da-5010634d909a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import wandb\n",
    "if __name__ == '__main__':\n",
    "    wandb.login(key = '04b7c2f62c8431e510e831fc18ac5e786a022591')\n",
    "    wandb.init(project = '1cbn specnorm  continue running from epoch ')\n",
    "\n",
    "    gan = GAN(discriminator = gan.discriminator , generator =gan.generator ,dataloader = train_dataloader  , val_data= test_dataloader,\n",
    "                          d_loss = hinge_loss , g_loss = generator_loss,lr = 0.0002/4)\n",
    "    tracker2 = MetricTracker()\n",
    "    trainer = Trainer(accelerator='auto' , max_epochs  = 100 ,callbacks = [TQDMProgressBar(1) ,tracker2]   , enable_model_summary=False ,num_sanity_val_steps=0 ,limit_train_batches=1.0, limit_val_batches=1.0)\n",
    "\n",
    "    trainer.fit( gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kExR9tCyvXLd",
    "outputId": "7d046014-fc83-476f-80ec-564e9f7842d2"
   },
   "outputs": [],
   "source": [
    "\n",
    "import wandb\n",
    "if __name__ == '__main__':\n",
    "    wandb.login(key = '04b7c2f62c8431e510e831fc18ac5e786a022591')\n",
    "    wandb.init(project = '1cbn specnorm  continue running from epoch 2')\n",
    "\n",
    "\n",
    "    gan = GAN(discriminator = gan.discriminator , generator =gan.generator  ,dataloader = train_dataloader  , val_data= test_dataloader,\n",
    "                          d_loss = hinge_loss , g_loss = generator_loss , lr = 0.0002/4)\n",
    "    tracker3= MetricTracker()\n",
    "    trainer = Trainer(accelerator='auto', max_epochs  = 100 ,callbacks = [TQDMProgressBar(1) ,tracker3]   , enable_model_summary=False ,num_sanity_val_steps=0 ,limit_train_batches=1.0, limit_val_batches=1.0)\n",
    "\n",
    "    trainer.fit( gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233,
     "referenced_widgets": [
      "606ab0a496b74757ad1cea382983c77f",
      "8271e7bbfaa84177943fdb2a969772d7",
      "791087e012614d3c84ed289248177052",
      "b3cf8441a90d428c8e11092f99a71af3",
      "de5e18d048df40e49b7cff242f862a8b",
      "eb1a8497ec344f7b9b9b34f4f3e60f17",
      "0d823f192c0543a3854016aaa79301fc",
      "f8a20b15f33a4b78bf4fa01d697c7605",
      "75d8cff7dc0e4a68ada13d12603a8a7f",
      "4dcad0f6389649ecb3d220a16b400f24",
      "3a89cb3c28d649fbad0895ee0182803c",
      "0506a092df46493d94161ea05f0c421f",
      "58da61e777ee447b98d7dfaf8283d736",
      "bd5282b75c4e4acd8387f7c1f881de7a",
      "f4ea5688f0664a448a27b739aec5ded2",
      "574e643f29134fb4b9f11dbb85998006",
      "bf4a851956354c6788c1c71ff8231b20",
      "c7366e8ddd5b4b82842a44be0fb6aaff",
      "da3d494e159f43d6b36af56359c208b8",
      "80d451afdf6645abbabb4ba1c841a2e2",
      "567af5bfc1a24d5096400fe3278c7783",
      "9f06c522cebe4c2aa09bead9f3f926f0"
     ]
    },
    "id": "AY1yVcddmDxd",
    "outputId": "c5bd4b89-136a-400f-a185-1906092a3765"
   },
   "outputs": [],
   "source": [
    "import torch_fidelity\n",
    "wrapped_generator = torch_fidelity.GenerativeModelModuleWrapper(gan.generator, 128, 'normal', 10)\n",
    "\n",
    "metrics = torch_fidelity.calculate_metrics(\n",
    "    input1=wrapped_generator, \n",
    "    input2='cifar10-val', \n",
    "    input1_model_num_samples = 10000, #size of cifar10 validation set\n",
    "    cuda=True, \n",
    "    isc=False, \n",
    "    fid=True, \n",
    "    kid=False, \n",
    "    verbose=False,\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07jD-s6gDFyb"
   },
   "outputs": [],
   "source": [
    "torch.save(gan.generator.state_dict(),'finalmodel.pth' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPh7P9szpjTj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combined = pd.concat((pd.DataFrame(tracker1.collection), pd.DataFrame(tracker2.collection) , pd.DataFrame(tracker3.collection)),ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming you have tracker1, tracker2, and tracker3 objects\n",
    "# df1 = pd.DataFrame(tracker1.collection)\n",
    "# df2 = pd.DataFrame(tracker2.collection)\n",
    "# df3 = pd.DataFrame(tracker3.collection)\n",
    "\n",
    "# # Find the common columns between all DataFrames\n",
    "# common_columns = set(df1.columns) & set(df2.columns) & set(df3.columns)\n",
    "\n",
    "# # Ensure that all DataFrames have the same columns and fill missing columns with NaN\n",
    "# df1 = df1.reindex(columns=common_columns)\n",
    "# df2 = df2.reindex(columns=common_columns)\n",
    "# df3 = df3.reindex(columns=common_columns)\n",
    "\n",
    "# # Concatenate DataFrames\n",
    "# combined = pd.concat([df1, df2, df3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLfyKMvA_-2U"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotlearningcurve(history):\n",
    "    plt.figure(figsize = (16,9))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(list(history['d_loss']) , label = 'Discriminator Loss')\n",
    "    plt.plot(list(history['g_loss'] ), label = 'Generator Loss')\n",
    "    plt.title('Learning Curve - loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend( loc='upper left')\n",
    "    plt.ylim(bottom = 0 )\n",
    "    plt.subplot(122)\n",
    "    plt.plot(list(history['kid'] ), label = 'KID')\n",
    "    plt.title('Learning Curve - KID')\n",
    "    plt.ylabel('KID')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend( loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "Km6nWgCoD61X",
    "outputId": "f10a2716-9d37-4a77-c2b4-8b90ac52de94"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plotlearningcurve(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su6f4lvxT4GS"
   },
   "source": [
    "- I realise that although this network is converging, it is doing so very slowly, hence, I decrease the learning rate to 0.0002 /4 = 0.00005 after 80 epochs leading to  decrease in discriminator loss and increase in generator loss and make them closer to convergence.\n",
    "\n",
    "- The rlc regularisation achieved a slight improvement in performance with FID of 18.74\n",
    "\n",
    "- The pinkish tint seemed to be removed with the addition of the rlc regularisation\n",
    "\n",
    "- From images generated during training above, the dogs, vehicles and hourses and birds look quite realistic \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3et1Wnoa6Rx"
   },
   "source": [
    "### Generate 100 images per class, 1000 images in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KD9QAxBzKlxs"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_img_per_class(imgs,labels ):\n",
    "    label_names = [\"Airplane\",\"Car\", \"Bird\", \"Cat\",\"Deer\",\"Dog\",\"Frog\",\"Horse\", \"Ship\",\"Truck\",]\n",
    "    fig, ax = plt.subplots(10, 10, figsize=(15, 15))\n",
    "    for img, label, subplot in zip(imgs, labels, ax.ravel()):\n",
    "        subplot.imshow(img.permute(1, 2, 0))\n",
    "        subplot.axis(\"off\")\n",
    "        name = label_names[label]\n",
    "        subplot.set_title(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YPsjrafjSGW9",
    "outputId": "795f96e8-02cf-45d7-c259-d5fbec0dee54"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  for class_index in range(10):\n",
    "    labels = torch.LongTensor(torch.full((128,), class_index)).cuda()\n",
    "    z = torch.randn(128, 128).cuda()\n",
    "    images = generator(z, labels).cpu()\n",
    "    fig = plot_img_per_class(images, labels.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQ90PPIZdB9m"
   },
   "source": [
    "- Images generally look realistic\n",
    "- Model performs better on vehicles and horses\n",
    "- Ships look the most realistic\n",
    "- cats deers and frogs look a bit weird\n",
    "- Model has trouble learning frogs as they have low resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_lightning.core import LightningModule\n",
    "# from pytorch_lightning.trainer import Trainer\n",
    "# import torch_fidelity\n",
    "# import numpy as np \n",
    "# import wandb\n",
    "# import collections \n",
    "# import torch\n",
    "# import torchmetrics\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "# def hinge_loss(dpred_real, dpred_fake):\n",
    "#     return (-torch.minimum(torch.tensor(0.0, dtype=torch.float, device=dpred_real.device), dpred_real - 1.0).mean()\n",
    "#             - torch.minimum(torch.tensor(0.0, dtype=torch.float, device=dpred_fake.device), -dpred_fake - 1.0).mean())\n",
    "\n",
    "# def rlc_reg(dpred_real, dpred_fake):\n",
    "#     regularization_loss = (dpred_real - 1.0).norm(dim=-1).pow(2).mean() + (dpred_fake - 1.0).norm(dim=-1).pow(2).mean()\n",
    "#     return 0.15 * regularization_loss\n",
    "\n",
    "# def r1_reg(dpred_real, dpred_fake):\n",
    "#     regularization_loss = (dpred_real - 1.0).norm(dim=-1).pow(2).mean() + (dpred_fake - 1.0).norm(dim=-1).pow(2).mean()\n",
    "#     return 0.15 * regularization_loss\n",
    "\n",
    "# def discriminator_loss(dpred_real, dpred_fake, real_img):\n",
    "#     return hinge_loss(dpred_real, dpred_fake) + r1_reg(dpred_real, real_img)\n",
    "\n",
    "# def generator_loss(pred):\n",
    "#     return -torch.mean(pred)\n",
    "\n",
    "# class GAN(LightningModule):\n",
    "#     def __init__(self,\n",
    "#                  discriminator, \n",
    "#                  generator, \n",
    "#                  dataloader,\n",
    "#                  val_data,\n",
    "#                  d_loss,\n",
    "#                  g_loss,\n",
    "#                  latent_dim: int = 128,\n",
    "#                  lr: float = 0.0002,\n",
    "#                  b1: float = 0.3,\n",
    "#                  b2: float = 0.999,\n",
    "#                  batch_size: int = 128,\n",
    "#                  n_discriminator_updates=1,\n",
    "#                  metricfreq=5,\n",
    "#                  **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.data = dataloader\n",
    "#         self.n_discriminator_updates = n_discriminator_updates\n",
    "#         self.val_data = val_data\n",
    "#         self.generator = generator\n",
    "#         self.discriminator = discriminator\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.lr = lr\n",
    "#         self.b1 = b1\n",
    "#         self.b2 = b2\n",
    "#         self.batch_size = batch_size\n",
    "#         self.g_loss = g_loss\n",
    "#         self.d_loss = d_loss\n",
    "#         self.epoch_counter = self.current_epoch\n",
    "#         self.metrics = collections.defaultdict(list)\n",
    "#         self.automatic_optimization = False\n",
    "#         self.metricsfreq = metricfreq\n",
    "#         self.d_loss_epoch = []\n",
    "#         self.g_loss_epoch = []\n",
    "#         self.kid = torchmetrics.image.kid.KernelInceptionDistance(subset_size=128)\n",
    "\n",
    "#     def forward(self, *z):\n",
    "#         return self.generator(*z)\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         imgs, labels = batch\n",
    "#         imgs.requires_grad = True\n",
    "\n",
    "#         g_opt, d_opt = self.optimizers()\n",
    "\n",
    "#         z = torch.randn(imgs.shape[0], self.latent_dim)\n",
    "#         z = z.type_as(imgs)\n",
    "\n",
    "#         if batch_idx % self.n_discriminator_updates == 0:\n",
    "#             pred_false = generator_loss(self.discriminator(self(z, labels), labels))\n",
    "#             g_loss = pred_false\n",
    "\n",
    "#             g_opt.zero_grad()\n",
    "#             self.manual_backward(g_loss)\n",
    "#             g_opt.step()\n",
    "#             self.g_loss = g_loss\n",
    "\n",
    "#         fake_img = self(z, labels)\n",
    "#         realpred = self.discriminator(imgs, labels)\n",
    "#         fakepred = self.discriminator(fake_img, labels)\n",
    "#         d_loss = discriminator_loss(realpred, fakepred, imgs)\n",
    "\n",
    "#         d_opt.zero_grad()\n",
    "#         self.manual_backward(d_loss)\n",
    "#         d_opt.step()\n",
    "#         self.log('g_loss', self.g_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "#         self.log('d_loss', d_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         lr = self.lr\n",
    "#         b1 = self.b1\n",
    "#         b2 = self.b2\n",
    "\n",
    "#         opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "#         opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "#         return opt_g, opt_d\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         return self.data\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return self.val_data\n",
    "\n",
    "#     def validation_step(self, b, bid):\n",
    "#         pass\n",
    "\n",
    "#     def on_validation_epoch_end(self, batch):\n",
    "#         wrapped_generator = torch_fidelity.GenerativeModelModuleWrapper(self.generator, self.latent_dim, 'normal', 10)\n",
    "\n",
    "#         metrics = torch_fidelity.calculate_metrics(\n",
    "#             input1=wrapped_generator,\n",
    "#             input2='cifar10-val',\n",
    "#             input1_model_num_samples=10000,\n",
    "#             cuda=True,\n",
    "#             isc=False,\n",
    "#             fid=False,\n",
    "#             kid=True,\n",
    "#             verbose=False,\n",
    "#         )\n",
    "#         self.log(\"kid\", metrics['kernel_inception_distance_mean'], prog_bar=True, logger=True)\n",
    "\n",
    "#         metricdict = {\"epoch\": self.current_epoch, \"kid\": metrics['kernel_inception_distance_mean']}\n",
    "#         print(metricdict)\n",
    "\n",
    "#         disstr = f\"Discriminator-Epoch{self.current_epoch},KID={metrics['kernel_inception_distance_mean']}.pth\"\n",
    "#         genstr = f\"Generator-Epoch{self.current_epoch},KID={metrics['kernel_inception_distance_mean']}.pth\"\n",
    "\n",
    "#         torch.save(self.discriminator.state_dict(), disstr)\n",
    "#         torch.save(self.generator.state_dict(), genstr)\n",
    "\n",
    "#         dis_name = wandb.util.make_artifact_name_safe(f\"Discriminator-{wandb.run.name}\")\n",
    "#         gen_name = wandb.util.make_artifact_name_safe(f\"Generator-{wandb.run.name}\")\n",
    "#         dis_artifact = wandb.Artifact(dis_name, type=\"model\")\n",
    "#         gen_artifact = wandb.Artifact(gen_name, type=\"model\")\n",
    "\n",
    "#         dis_artifact.add_file(disstr)\n",
    "#         gen_artifact.add_file(genstr)\n",
    "#         wandb.run.log_artifact(dis_artifact, aliases=[\"latest\", f\"Discriminator_epoch_{self.current_epoch}\"])\n",
    "#         wandb.run.log_artifact(gen_artifact, aliases=[\"latest\", f\"Generator_epoch_{self.current_epoch}\"])\n",
    "\n",
    "#         os.remove(disstr)\n",
    "#         os.remove(genstr)\n",
    "\n",
    "#     def on_train_epoch_end(self, data):\n",
    "#         num_cols = 10\n",
    "#         num_rows = 5\n",
    "#         random_latent_vectors = torch.randn(num_cols * num_rows, self.latent_dim).cuda()\n",
    "#         generated_images = self.generator(random_latent_vectors, torch.arange(0, 10).repeat_interleave(5).type(torch.IntTensor).cuda()).cpu().detach().numpy()\n",
    "#         generated_images = (generated_images + 1) / 2\n",
    "\n",
    "#         plt.figure(figsize=(num_cols * 1.0, num_rows * 1.0))\n",
    "#         for row in range(num_rows):\n",
    "#             for col in range(num_cols):\n",
    "#                 index = row * num_cols + col\n",
    "#                 plt.subplot(num_rows, num_cols, index + 1)\n",
    "#                 plt.imshow(np.transpose(generated_images[index], (1, 2, 0)))\n",
    "#                 plt.axis(\"off\")\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "\n",
    "# from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "# class MetricTracker(Callback):\n",
    "#     def __init__(self):\n",
    "#         self.collection = collections.defaultdict(list)\n",
    "\n",
    "#     def on_train_epoch_end(self, trainer, ganmodule):\n",
    "#         elogs = trainer.logged_metrics\n",
    "#         self.collection['epoch'].append(ganmodule.current_epoch)\n",
    "#         self.collection['d_loss'].append(elogs['d_loss_epoch'])\n",
    "#         self.collection['g_loss'].append(elogs['g_loss_epoch'])\n",
    "\n",
    "#     def on_validation_epoch_end(self, trainer, module):\n",
    "#         if 'kid' in trainer.logged_metrics:\n",
    "#             self.collection['kid'].append(trainer.logged_metrics['kid'])\n",
    "#             d = {}\n",
    "#             for k, v in self.collection.items():\n",
    "#                 d[k] = v[-1]\n",
    "#             wandb.log(d)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a06e7f6985fb5679fa9de73270e0bcf21a4bda82b875ec978b8d7717e8ae693"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
